{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_part_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqDZbGK8TLOeN/YHTWpwhb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZY3opRL3vG9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ej4IHI97O3I"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVq9LKYN7x__"
      },
      "source": [
        "# inspect data\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep8DQvEl8Shh"
      },
      "source": [
        "## Creating data loaders (prepering the data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGV0lBO9sno"
      },
      "source": [
        "# Setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training Images:\")\n",
        "train_data_10_prec = train_datagen.flow_from_directory(train_dir,\n",
        "                                                       target_size=IMAGE_SHAPE,\n",
        "                                                       batch_size=BATCH_SIZE,\n",
        "                                                       class_mode=\"categorical\")\n",
        "\n",
        "print(\"Test Images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                                       target_size=IMAGE_SHAPE,\n",
        "                                                       batch_size=BATCH_SIZE,\n",
        "                                                       class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4n_qfPm-pJ5"
      },
      "source": [
        "## Setting up callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyUJMZzX_94y"
      },
      "source": [
        "# Create Tensorboard callback\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSg55mS-BPKz"
      },
      "source": [
        "## Creating models using TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCWuaEGxFPuH"
      },
      "source": [
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru04p9cFH1UR"
      },
      "source": [
        "# Import Dep\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbc4svHLIMqg"
      },
      "source": [
        "# Create model function\n",
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  model_url: TF Hub url for feature extraction\n",
        "  num_classes: num of neurons in output layer\n",
        "\n",
        "  returns uncompiled TF model\n",
        "  \"\"\"\n",
        "  # Download the preload model\n",
        "  feature_extractor_layer  = hub.KerasLayer(model_url,\n",
        "                                            trainable=False,\n",
        "                                            name=\"feature_extraction_layer\",\n",
        "                                            input_shape=IMAGE_SHAPE+(3,))\n",
        "  \n",
        "  # Create model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_classes, activation=\"softmax\", name=\"output_model\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9EjgoE7JbRx"
      },
      "source": [
        "## Creating ResNet Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnEYk6xlJ7vT"
      },
      "source": [
        "# create resnet model\n",
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data_10_prec.num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n3nv5hnKNAA"
      },
      "source": [
        "resnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0-NLtsCKade"
      },
      "source": [
        "# Compile a  resnet model\n",
        "resnet_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtScowp9K2Dw"
      },
      "source": [
        "history_resnet = resnet_model.fit(\n",
        "    train_data_10_prec,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=len(train_data_10_prec),\n",
        "    validation_data=test_data,\n",
        "    validation_steps=len(test_data),\n",
        "    callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                           experiment_name=\"resnet50V2\")]\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gckPHPj4LyPJ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Plot the validation and training curves separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.figure(figsize=(18,7))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss, label=\"Training Loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
        "  plt.title(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot Accuracy\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, accuracy, label=\"Training Accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"Validation Accuracy\")\n",
        "  plt.title(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ7Pt4gaOyt5"
      },
      "source": [
        "plot_loss_curves(history_resnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v5hTwD-O5Q_"
      },
      "source": [
        "## Creating EfficientNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKPQ-dn7PgW_"
      },
      "source": [
        "effnet_model = create_model(efficientnet_url, train_data_10_prec.num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD0OEBLmQzrm"
      },
      "source": [
        "effnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmSRGaRPzLn"
      },
      "source": [
        "# Compiling the model\n",
        "effnet_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc4z4QNJQCdQ"
      },
      "source": [
        "history_effnet = effnet_model.fit(\n",
        "    train_data_10_prec,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=len(train_data_10_prec),\n",
        "    validation_data=test_data,\n",
        "    validation_steps=len(test_data),\n",
        "    callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                           experiment_name=\"efficientnetB0\")]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxtE7rEaQnTy"
      },
      "source": [
        "plot_loss_curves(history_effnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmVvyc1RIDY"
      },
      "source": [
        "## Comparing models on TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NziVN6TUTG31"
      },
      "source": [
        "# Upload tensorboards dev records\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "  --name \"EffNetB0 vs ResNet50v2\" \\\n",
        "  --description \"Comparing image classification models\" \\\n",
        "  --one_shot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80wt3u8JUT5B"
      },
      "source": [
        "!tensorboard dev list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKQ-IQG0ViTK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}